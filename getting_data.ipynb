{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 # needed to get database exception errors when uploading dataframe\n",
    "import requests # package for getting data from the web\n",
    "from zipfile import * # package for unzipping zip files\n",
    "from sql_functions import get_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='data/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(year, month):\n",
    "    # Get the file from the website https://transtats.bts.gov\n",
    "    zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "    url = (f'https://transtats.bts.gov/PREZIP/{zip_file}')\n",
    "    # Download the database\n",
    "    r = requests.get(f'{url}', verify=False)\n",
    "    # Save database to local file storage\n",
    "    with open(path+zip_file, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        print(f'--> zip_file with name: {zip_file} downloaded succesfully.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(year, month):\n",
    "    # Get the file from the website https://transtats.bts.gov\n",
    "    zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "    with ZipFile(path+zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "        csv_file =  zip_ref.namelist()[0]\n",
    "        print(f'--> zip_file was succesfully extracted to: {csv_file}.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_list = [2011, 2012] # list of years you want to look at (can of course also be a single year)\n",
    "months_list = [10, 11] # list of months you want to look at (can of course also be a single month)\n",
    "\n",
    "# download flights data as zipfile(s)\n",
    "# we use a nested loop to specify the years and months to define the range of the data we would like to have \n",
    "for year in years_list:\n",
    "    for month in months_list:\n",
    "        download_data(year, month)\n",
    "        extract_zip(year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_10_12 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2012_10.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_oct_2012 = pd.read_csv(path+csv_file_10_12, low_memory = False)\n",
    "display(df_oct_2012.shape)\n",
    "display(df_oct_2012.head())\n",
    "\n",
    "csv_file_11_12 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2012_11.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_nov_2012 = pd.read_csv(path+csv_file_11_12, low_memory = False)\n",
    "display(df_nov_2012.shape)\n",
    "display(df_nov_2012.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from downloaded file that are to be kept\n",
    "\n",
    "columns_to_keep = [\n",
    "                'FlightDate',\n",
    "                'DepTime',\n",
    "                'CRSDepTime',\n",
    "                'DepDelay',\n",
    "                'ArrTime',\n",
    "                'CRSArrTime',\n",
    "                'ArrDelay',\n",
    "                'Reporting_Airline',\n",
    "                'Tail_Number',\n",
    "                'Flight_Number_Reporting_Airline',\n",
    "                'Origin',\n",
    "                'Dest',\n",
    "                'AirTime',\n",
    "                'ActualElapsedTime',\n",
    "                'Distance',\n",
    "                'Cancelled',\n",
    "                'Diverted'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'cgn_analytics_24_3' # UPDATE 'TABLE_SCHEMA' based on schema used in class \n",
    "engine = get_engine() # assign engine to be able to query against the database\n",
    "\n",
    "table_name_sql = f'''SELECT COLUMN_NAME \n",
    "                    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "                    WHERE TABLE_NAME = 'flights'\n",
    "                    AND TABLE_SCHEMA ='{schema}'\n",
    "                    ORDER BY ordinal_position'''\n",
    "c_names = engine.execute(table_name_sql).fetchall()\n",
    "c_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names=[]\n",
    "for name in c_names:\n",
    "    new_column_names.append(name[0])\n",
    "new_column_names     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_airline_df(df):\n",
    "    '''\n",
    "    Transforms a df made from BTS csv file into a df that is ready to be uploaded to SQL\n",
    "    Set rows=0 for no filtering\n",
    "    '''\n",
    "\n",
    "    # Build dataframe including only the columns you want to keep\n",
    "    df_airline = df.loc[:,columns_to_keep]\n",
    "     \n",
    "    # Clean data types and NULLs\n",
    "    df_airline['FlightDate']= pd.to_datetime(df_airline['FlightDate'], yearfirst=True)\n",
    "    df_airline['CRSArrTime']= pd.to_numeric(df_airline['CRSArrTime'], downcast='integer', errors='coerce')\n",
    "    df_airline['Cancelled']= pd.to_numeric(df_airline['Cancelled'], downcast='integer')\n",
    "    df_airline['Diverted']= pd.to_numeric(df_airline['Diverted'], downcast='integer')\n",
    "    df_airline['ActualElapsedTime']= pd.to_numeric(df_airline['ActualElapsedTime'], downcast='integer', errors='coerce')\n",
    "    \n",
    "    # Rename columns\n",
    "    df_airline.columns = new_column_names\n",
    "    \n",
    "    return df_airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oct_2012_clean = clean_airline_df(df_oct_2012)\n",
    "df_oct_2012_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nov_2012_clean = clean_airline_df(df_nov_2012)\n",
    "df_nov_2012_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_airport(df, airports):\n",
    "    ''' Helper function for filtering the airline dataframe for a subset of airports'''\n",
    "    df_out = df.loc[(df.origin.isin(airports)) | (df.dest.isin(airports))]\n",
    "    return df_out\n",
    "\n",
    "\n",
    "airports=['JFK', 'LGA', 'EWR', 'PHL', 'BOS', 'DCA', 'IAD', 'BWI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(airports) > 0:\n",
    "    df_oct_2012_selected_airports = select_airport(df_oct_2012_clean, airports)\n",
    "else:\n",
    "    df_selected_airports = df_oct_2012_clean\n",
    "df_oct_2012_selected_airports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(airports) > 0:\n",
    "    df_nov_2012_selected_airports = select_airport(df_nov_2012_clean, airports)\n",
    "else:\n",
    "    df_selected_airports = df_nov_2012_clean\n",
    "df_nov_2012_selected_airports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_oct_2012_selected_airports, df_nov_2012_selected_airports])\n",
    "#combined_df['flight_date'] = pd.to_datetime(combined_df['date'])\n",
    "#start_date = '2012-10-22'\n",
    "#end_date = '2012-11-03'\n",
    "#filtered_df = combined_df[(combined_df['flight_date'] >= start_date) & (combined_df['flight_date'] <= end_date)]\n",
    "\n",
    "combined_df.reset_index(drop=True, inplace=True )\n",
    "#filtered_df.tail(15)\n",
    "combined_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_functions import get_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'flights_oct_nov_2012_sandy'\n",
    "engine = get_engine()\n",
    "schema = 'cgn_analytics_24_3'\n",
    "\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This may take some time ...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        combined_df.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataframe('''select * \n",
    "                   from cgn_analytics_24_3.flights_oct_nov_2012_sandy''')\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
