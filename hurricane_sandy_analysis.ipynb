{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCA analysis of flight stats during Hurricane Sandy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hurricane Sandy](hurricane-sandy-nasa-image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurricane Sandy hit the northeast coast of the United States on the 29th of October 2012 and dissipated on the 2nd of November 2012. The most affected cities were New York, Philadelphia, Boston, and Washington DC. Therefore, we're analyzing the following airports: \n",
    "\n",
    "**New York City:**\n",
    "* John F. Kennedy International Airport (JFK)\n",
    "* LaGuardia Airport (LGA)\n",
    "* Newark Liberty International Airport (EWR)\n",
    "\n",
    "**Philadelphia:**\n",
    "* Philadelphia International Airport (PHL)\n",
    "\n",
    "**Boston:**\n",
    "* Logan International Airport (BOS)\n",
    "\n",
    "**Washington D.C.:**\n",
    "* Ronald Reagan Washington National Airport (DCA)\n",
    "* Washington Dulles International Airport (IAD)\n",
    "* Baltimore/Washington International Thurgood Marshall Airport (BWI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypotheses: \n",
    "1. Hurricane Sandy caused a drastic increase in flight cancellations from the 29th of October 2012 to 2nd of November 2012 from the following airports: JFK, LGA, EWR, PHL BOS, DCA, IAD, BWI.  \n",
    "2. On the 29th of October 2012, most flights landing in airports JFK, LGA, EWR, PHL BOS, DCA, IAD, BWI were diverted. \n",
    "3. By comparing weather and flight data from 2011 and 2012, it's apparent that Hurricane Sandy was the primary cause for a large amount of flight cancellations in 2012. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import psycopg2 # needed to get database exception errors when uploading dataframe\n",
    "from zipfile import * # package for unzipping zip files\n",
    "from sql_functions import get_engine\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  tavg  tmin  tmax  prcp  snow   wdir  wspd  wpgt    pres  tsun  \\\n",
      "0  2012-10-01  17.1  12.2  22.2   0.0   0.0  262.0  18.4  None  1012.2  None   \n",
      "1  2012-10-02  18.9  17.2  21.7   8.4   0.0    NaN   9.4  None  1015.8  None   \n",
      "2  2012-10-03  20.3  18.3  23.3   0.0   0.0    NaN   6.1  None  1017.7  None   \n",
      "3  2012-10-04  20.8  19.4  23.9  10.4   0.0    NaN   5.4  None  1019.3  None   \n",
      "4  2012-10-05  20.7  16.1  25.0   0.0   0.0    NaN  12.6  None  1016.8  None   \n",
      "\n",
      "  airport_code  \n",
      "0          JFK  \n",
      "1          JFK  \n",
      "2          JFK  \n",
      "3          JFK  \n",
      "4          JFK  \n"
     ]
    }
   ],
   "source": [
    "#Weather data for 2012\n",
    "#API URL and headers\n",
    "#Weather data for 2011\n",
    "url = 'https://meteostat.p.rapidapi.com/point/daily'\n",
    "headers = {\n",
    "   \"x-rapidapi-host\": 'meteostat.p.rapidapi.com',\n",
    "   \"x-rapidapi-key\": os.getenv('x-rapidapi-key')  # Ensure this environment variable is set\n",
    "}\n",
    "\n",
    "#airports and their coordinates\n",
    "airports = {\n",
    "    \"JFK\": {\"lat\": 40.6413, \"lon\": -73.7781},  # John F. Kennedy International Airport\n",
    "    \"LGA\": {\"lat\": 40.7769, \"lon\": -73.8740},  # LaGuardia Airport\n",
    "    \"EWR\": {\"lat\": 40.6895, \"lon\": -74.1745},  # Newark Liberty International Airport\n",
    "    \"PHL\": {\"lat\": 39.8729, \"lon\": -75.2437},  # Philadelphia International Airport\n",
    "    \"BOS\": {\"lat\": 42.3656, \"lon\": -71.0096},  # Boston Logan International Airport\n",
    "    \"DCA\": {\"lat\": 38.8512, \"lon\": -77.0402},  # Ronald Reagan Washington National Airport\n",
    "    \"IAD\": {\"lat\": 38.9531, \"lon\": -77.4565},  # Washington Dulles International Airport\n",
    "    \"BWI\": {\"lat\": 39.1754, \"lon\": -76.6684}   # Baltimore/Washington International Thurgood Marshall Airport\n",
    "}\n",
    "\n",
    "#date range\n",
    "start_date = \"2012-10-01\"\n",
    "end_date = \"2012-11-30\"\n",
    "weather_data_2012 = []\n",
    "\n",
    "for airport_code, coordinates in airports.items():\n",
    "    parameters = {\n",
    "        \"lat\": coordinates[\"lat\"],\n",
    "        \"lon\": coordinates[\"lon\"],\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"units\": \"metric\"\n",
    "    }\n",
    "    time.sleep(1) \n",
    "    response = requests.get(url, headers=headers, params=parameters)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for daily_data in data['data']:\n",
    "            daily_data['airport_code'] = airport_code\n",
    "            weather_data_2012.append(daily_data)\n",
    "    else:\n",
    "        print(f\"Error fetching data for {airport_code}: {response.status_code} - {response.text}\") \n",
    "\n",
    "#list of dictionaries to a DataFrame\n",
    "weather_df_2012 = pd.DataFrame(weather_data_2012)\n",
    "\n",
    "\n",
    "print(weather_df_2012.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning steps for 2012\n",
    "#Dropping empty columns\n",
    "weather_df_2012 = weather_df_2012.drop(columns=['wpgt', 'tsun'])\n",
    "\n",
    "#Filling missing values in wspd with 0\n",
    "weather_df_2012['wspd'].fillna(0, inplace=True)\n",
    "\n",
    "#Convert date column to datetime\n",
    "weather_df_2012['date'] = pd.to_datetime(weather_df_2012['date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write records stored in a dataframe to SQL database\n",
    "table_name = 'weather_data_2012'\n",
    "schema = 'cgn_analytics_24_3'\n",
    "engine = get_engine()\n",
    "\n",
    "if engine!=None:\n",
    "    try:\n",
    "        weather_df_2012.to_sql(table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # your class schema\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avg wind speed 2012\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.lineplot(data=weather_df_2012, x='date', y='wspd', hue='airport_code', marker='o')\n",
    "plt.title('Avg Wind Speed Oct - Nov 2012')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Avg Wind Speed (km/h)')\n",
    "dates = weather_df_2012['date'].unique()\n",
    "plt.xticks(dates[::2], rotation=45)\n",
    "plt.legend(title='Airport Code')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversions_df = get_dataframe('''select *, flight_date as date\n",
    "                   from cgn_analytics_24_3.diverted_per_day_2012_sandy''')\n",
    "\n",
    "diversions_df['date'] = pd.to_datetime(diversions_df['date'])\n",
    "diversions_2012 = diversions_df.drop(columns=['flight_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg_diversions = diversions_2012.groupby('date')['total_diverted'].mean().reset_index()\n",
    "daily_avg_diversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avg daily diversions \n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(daily_avg_diversions['date'], daily_avg_diversions['total_diverted'], marker='o')\n",
    "plt.title('Daily Average Total Diversions Over Time (2012)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Total Diversions')\n",
    "dates = weather_df_2012['date'].unique()\n",
    "plt.xticks(dates[::2], rotation=45)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_functions import get_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancellations = get_dataframe('''select * \n",
    "                   from cgn_analytics_24_3.cancellations_per_day_2012_sandy''')\n",
    "df_cancellations.rename(columns= {'flight_date': 'date'}, inplace=True)\n",
    "df_cancellations.rename(columns= {'origin': 'airport_code'}, inplace=True)\n",
    "df_cancellations.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 9))\n",
    "sns.lineplot(data=df_cancellations, x='date', y='cancellation_percentage', marker='o')\n",
    "plt.xticks(df_cancellations.date[::2], rotation=45)\n",
    "plt.title('Daily avg procent of flights cancellations in October-November 2012')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percent of cancelled flights')\n",
    "#plt.legend(title= 'Origin Airport Code')\n",
    "#plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = get_dataframe('select * from cgn_analytics_24_3.weather_data_2012')\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_c = pd.merge(df_cancellations, df_weather, on=['date', 'airport_code'] )\n",
    "df_w_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 9))\n",
    "sns.lineplot(data=df_cancellations, x='flight_date', y='cancellation_percentage', hue='origin', marker='o')\n",
    "plt.xticks(df_cancellations.flight_date[::16], rotation=45)\n",
    "plt.title('Flights cancellations October-November 2012')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percentage of cancelled flights')\n",
    "plt.legend(title= 'Origin Airport Code')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 9))\n",
    "sns.lineplot(data=df_w_c, x='date', y='cancellation_percentage', marker='o')\n",
    "plt.xticks(df_w_c.date[::16], rotation=45)\n",
    "plt.title('Flights cancellations October-November 2012')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percentage of cancelled flights')\n",
    "plt.legend(title= 'Origin Airport Code')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diverted = get_dataframe('select * from cgn_analytics_24_3.diverted_per_day_2012_sandy')\n",
    "df_diverted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 9))\n",
    "sns.lineplot(data=df_diverted, x='flight_date', y='diverted_percentage', hue='dest', marker='o')\n",
    "plt.xticks(df_diverted.flight_date[::16], rotation=45)\n",
    "plt.title('Flights divertions October-November 2012')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percentage of diverted flights')\n",
    "plt.legend(title= 'Origin Airport Code')\n",
    "#plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = get_dataframe('select * from cgn_analytics_24_3.weather_data_2012')\n",
    "df_weather.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 9))\n",
    "sns.lineplot(data = df_w_c, x='date', y= 'wspd', marker='o', label='Wind Speed')\n",
    "sns.lineplot(data = df_w_c, x='date', y= 'prcp', marker='o', label='Precipitation')\n",
    "sns.lineplot(data= df_w_c, x='date', y='cancellation_percentage', marker='o', label='Cancellation Percentage')\n",
    "plt.xticks(df_w_c.date[::16], rotation=45)\n",
    "plt.title('Flights cancellation to weather conditions October-November 2012')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "#plt.legend(title='Wind speed')\n",
    "\n",
    "#plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 9))\n",
    "sns.lineplot(data=df_weather, x='date', y='pres', marker='o')\n",
    "#sns.lineplot(data = df_w_c, x='date', y= 'cancellation_percentage', marker='o')\n",
    "\n",
    "plt.xticks(df_weather.date[::4], rotation=45)\n",
    "plt.title('Air pressure October-November 2012')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Pressure')\n",
    "#plt.legend(title= 'Origin Airport Code')\n",
    "#plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_avg_daily = df_weather.groupby('date')['pres'].mean().reset_index()\n",
    "\n",
    "pressure_avg_daily['date'] = pd.to_datetime(pressure_avg_daily['date'])\n",
    "pressure_avg_daily.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_cancellations_df = pd.merge(pressure_avg_daily, cancellations_grouped_df, on='date')\n",
    "pres_cancellations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 9))\n",
    "sns.lineplot(data=pres_cancellations_df, x='date', y='pres', marker='o')\n",
    "sns.lineplot(data=pres_cancellations_df, x='date', y='total_cancellations', marker='o')\n",
    "plt.xticks(df_weather.date[::3], rotation=45)\n",
    "#plt.title('Flights divertions October-November 2012')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('value')\n",
    "#plt.legend(title= 'Origin Airport Code')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weather data for 2011\n",
    "#API URL and headers\n",
    "url = 'https://meteostat.p.rapidapi.com/point/daily'\n",
    "headers = {\n",
    "   \"x-rapidapi-host\": 'meteostat.p.rapidapi.com',\n",
    "   \"x-rapidapi-key\": os.getenv('x-rapidapi-key')  # Ensure this environment variable is set\n",
    "}\n",
    "\n",
    "#airports and their coordinates\n",
    "airports = {\n",
    "    \"JFK\": {\"lat\": 40.6413, \"lon\": -73.7781},  # John F. Kennedy International Airport\n",
    "    \"LGA\": {\"lat\": 40.7769, \"lon\": -73.8740},  # LaGuardia Airport\n",
    "    \"EWR\": {\"lat\": 40.6895, \"lon\": -74.1745},  # Newark Liberty International Airport\n",
    "    \"PHL\": {\"lat\": 39.8729, \"lon\": -75.2437},  # Philadelphia International Airport\n",
    "    \"BOS\": {\"lat\": 42.3656, \"lon\": -71.0096},  # Boston Logan International Airport\n",
    "    \"DCA\": {\"lat\": 38.8512, \"lon\": -77.0402},  # Ronald Reagan Washington National Airport\n",
    "    \"IAD\": {\"lat\": 38.9531, \"lon\": -77.4565},  # Washington Dulles International Airport\n",
    "    \"BWI\": {\"lat\": 39.1754, \"lon\": -76.6684}   # Baltimore/Washington International Thurgood Marshall Airport\n",
    "}\n",
    "\n",
    "#date range\n",
    "start_date = \"2011-10-01\"\n",
    "end_date = \"2011-11-30\"\n",
    "weather_data_2011 = []\n",
    "\n",
    "for airport_code, coordinates in airports.items():\n",
    "    parameters = {\n",
    "        \"lat\": coordinates[\"lat\"],\n",
    "        \"lon\": coordinates[\"lon\"],\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"units\": \"metric\"\n",
    "    }\n",
    "    time.sleep(1)\n",
    "    response = requests.get(url, headers=headers, params=parameters)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for daily_data in data['data']:\n",
    "            daily_data['airport_code'] = airport_code\n",
    "            weather_data_2011.append(daily_data)\n",
    "    else:\n",
    "        print(f\"Error fetching data for {airport_code}: {response.status_code} - {response.text}\") \n",
    "\n",
    "#list of dictionaries to a DataFrame\n",
    "weather_df_2011 = pd.DataFrame(weather_data_2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning steps for 2011\n",
    "#Dropping empty columns\n",
    "weather_df_2011 = weather_df_2011.drop(columns=['wpgt', 'tsun'])\n",
    "\n",
    "#Filling missing values in wspd with 0\n",
    "weather_df_2011['wspd'].fillna(0, inplace=True)\n",
    "\n",
    "#Convert date column to datetime\n",
    "weather_df_2011['date'] = pd.to_datetime(weather_df_2011['date'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write records stored in a dataframe to SQL database\n",
    "table_name = 'weather_data_2011'\n",
    "schema = 'cgn_analytics_24_3'\n",
    "engine = get_engine()\n",
    "\n",
    "if engine!=None:\n",
    "    try:\n",
    "        weather_df_2011.to_sql(table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # your class schema\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='data/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(year, month):\n",
    "    # Get the file from the website https://transtats.bts.gov\n",
    "    zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "    url = (f'https://transtats.bts.gov/PREZIP/{zip_file}')\n",
    "    # Download the database\n",
    "    r = requests.get(f'{url}', verify=False)\n",
    "    # Save database to local file storage\n",
    "    with open(path+zip_file, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        print(f'--> zip_file with name: {zip_file} downloaded succesfully.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(year, month):\n",
    "    # Get the file from the website https://transtats.bts.gov\n",
    "    zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_{year}_{month}.zip'\n",
    "    with ZipFile(path+zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "        csv_file =  zip_ref.namelist()[0]\n",
    "        print(f'--> zip_file was succesfully extracted to: {csv_file}.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_list = [2011] # list of years you want to look at (can of course also be a single year)\n",
    "months_list = [10, 11] # list of months you want to look at (can of course also be a single month)\n",
    "\n",
    "# download flights data as zipfile(s)\n",
    "# we use a nested loop to specify the years and months to define the range of the data we would like to have \n",
    "for year in years_list:\n",
    "    for month in months_list:\n",
    "        download_data(year, month)\n",
    "        extract_zip(year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_10_11 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2011_10.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_oct_2011 = pd.read_csv(path+csv_file_10_11, low_memory = False)\n",
    "display(df_oct_2011.shape)\n",
    "display(df_oct_2011.head())\n",
    "\n",
    "csv_file_11_11 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2011_11.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_nov_2011 = pd.read_csv(path+csv_file_11_11, low_memory = False)\n",
    "display(df_nov_2011.shape)\n",
    "display(df_nov_2011.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from downloaded file that are to be kept\n",
    "\n",
    "columns_to_keep = [\n",
    "                'FlightDate',\n",
    "                'DepTime',\n",
    "                'CRSDepTime',\n",
    "                'DepDelay',\n",
    "                'ArrTime',\n",
    "                'CRSArrTime',\n",
    "                'ArrDelay',\n",
    "                'Reporting_Airline',\n",
    "                'Tail_Number',\n",
    "                'Flight_Number_Reporting_Airline',\n",
    "                'Origin',\n",
    "                'Dest',\n",
    "                'AirTime',\n",
    "                'ActualElapsedTime',\n",
    "                'Distance',\n",
    "                'Cancelled',\n",
    "                'Diverted'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'cgn_analytics_24_3' # UPDATE 'TABLE_SCHEMA' based on schema used in class \n",
    "engine = get_engine() # assign engine to be able to query against the database\n",
    "\n",
    "table_name_sql = f'''SELECT COLUMN_NAME \n",
    "                    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "                    WHERE TABLE_NAME = 'flights'\n",
    "                    AND TABLE_SCHEMA ='{schema}'\n",
    "                    ORDER BY ordinal_position'''\n",
    "c_names = engine.execute(table_name_sql).fetchall()\n",
    "c_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names=[]\n",
    "for name in c_names:\n",
    "    new_column_names.append(name[0])\n",
    "new_column_names     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_airline_df(df):\n",
    "    '''\n",
    "    Transforms a df made from BTS csv file into a df that is ready to be uploaded to SQL\n",
    "    Set rows=0 for no filtering\n",
    "    '''\n",
    "\n",
    "    # Build dataframe including only the columns you want to keep\n",
    "    df_airline = df.loc[:,columns_to_keep]\n",
    "     \n",
    "    # Clean data types and NULLs\n",
    "    df_airline['FlightDate']= pd.to_datetime(df_airline['FlightDate'], yearfirst=True)\n",
    "    df_airline['CRSArrTime']= pd.to_numeric(df_airline['CRSArrTime'], downcast='integer', errors='coerce')\n",
    "    df_airline['Cancelled']= pd.to_numeric(df_airline['Cancelled'], downcast='integer')\n",
    "    df_airline['Diverted']= pd.to_numeric(df_airline['Diverted'], downcast='integer')\n",
    "    df_airline['ActualElapsedTime']= pd.to_numeric(df_airline['ActualElapsedTime'], downcast='integer', errors='coerce')\n",
    "    \n",
    "    # Rename columns\n",
    "    df_airline.columns = new_column_names\n",
    "    \n",
    "    return df_airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_airline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oct_2011_clean = clean_airline_df(df_oct_2011)\n",
    "df_oct_2011_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nov_2011_clean = clean_airline_df(df_nov_2011)\n",
    "df_nov_2011_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_airport(df, airports):\n",
    "    ''' Helper function for filtering the airline dataframe for a subset of airports'''\n",
    "    df_out = df.loc[(df.origin.isin(airports)) | (df.dest.isin(airports))]\n",
    "    return df_out\n",
    "\n",
    "\n",
    "airports=['JFK', 'LGA', 'EWR', 'PHL', 'BOS', 'DCA', 'IAD', 'BWI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(airports) > 0:\n",
    "    df_oct_2011_selected_airports = select_airport(df_oct_2011_clean, airports)\n",
    "else:\n",
    "    df_selected_airports = df_oct_2011_clean\n",
    "df_oct_2011_selected_airports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(airports) > 0:\n",
    "    df_nov_2011_selected_airports = select_airport(df_nov_2011_clean, airports)\n",
    "else:\n",
    "    df_selected_airports = df_nov_2011_clean\n",
    "df_nov_2011_selected_airports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_oct_2011_selected_airports, df_nov_2011_selected_airports])\n",
    "#combined_df['flight_date'] = pd.to_datetime(combined_df['date'])\n",
    "#start_date = '2011-10-22'\n",
    "#end_date = '2011-11-03'\n",
    "#filtered_df = combined_df[(combined_df['flight_date'] >= start_date) & (combined_df['flight_date'] <= end_date)]\n",
    "\n",
    "combined_df.reset_index(drop=True, inplace=True )\n",
    "#filtered_df.tail(15)\n",
    "combined_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_functions import get_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'flights_oct_nov_2011_sandy'\n",
    "engine = get_engine()\n",
    "schema = 'cgn_analytics_24_3'\n",
    "\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This may take some time ...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        combined_df.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_functions import get_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataframe('''select * \n",
    "                   from cgn_analytics_24_3.flights_oct_nov_2011_sandy''')\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airport_data():\n",
    "    # Define the airports and date range\n",
    "    airports = ['JFK', 'LGA', 'EWR', 'PHL', 'BOS', 'DCA', 'IAD', 'BWI']\n",
    "    start_date = '2011-10-01'\n",
    "    end_date = '2011-12-01'\n",
    "\n",
    "    # Construct the SQL query\n",
    "    query = f'''\n",
    "    SELECT *\n",
    "    FROM cgn_analytics_24_3.flights_oct_nov_2011_sandy\n",
    "    WHERE origin IN ({', '.join([f\"'{airport}'\" for airport in airports])})\n",
    "      AND flight_date >= '{start_date}'\n",
    "      AND flight_date <= '{end_date}'\n",
    "    '''\n",
    "\n",
    "    # Execute the query and fetch the results into a dataframe\n",
    "    df = get_dataframe(query)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Call the function to get the airport data\n",
    "airport_data = get_airport_data()\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(airport_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting with separated airports - 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airport_data():\n",
    "    # Define the airports and date range\n",
    "    airports = ['JFK', 'LGA', 'EWR', 'PHL', 'BOS', 'DCA', 'IAD', 'BWI']\n",
    "    start_date = '2011-10-01'\n",
    "    end_date = '2011-12-01'\n",
    "\n",
    "    # Construct the SQL query\n",
    "    query = f'''\n",
    "    SELECT *\n",
    "    FROM cgn_analytics_24_3.flights_oct_nov_2011_sandy\n",
    "    WHERE origin IN ({', '.join([f\"'{airport}'\" for airport in airports])})\n",
    "      AND flight_date >= '{start_date}'\n",
    "      AND flight_date <= '{end_date}'\n",
    "    '''\n",
    "\n",
    "    # Assuming you have a method to execute the SQL query and fetch the results into a dataframe\n",
    "    # Replace 'execute_query_and_fetch_dataframe' with the actual method you use to execute the query\n",
    "    df_airport = get_dataframe(query)\n",
    "\n",
    "    return df_airport\n",
    "\n",
    "def get_weather_data():\n",
    "    # Define date range\n",
    "    start_date = '2011-10-01'\n",
    "    end_date = '2011-12-01'\n",
    "\n",
    "    # Construct the SQL query\n",
    "    query = f'''\n",
    "    SELECT date, wspd\n",
    "    FROM cgn_analytics_24_3.weather_data_2011\n",
    "    WHERE date >= '{start_date}'\n",
    "      AND date <= '{end_date}'\n",
    "    '''\n",
    "\n",
    "    # Assuming you have a method to execute the SQL query and fetch the results into a dataframe\n",
    "    # Replace 'execute_query_and_fetch_dataframe' with the actual method you use to execute the query\n",
    "    df_weather = get_dataframe(query)\n",
    "\n",
    "    return df_weather\n",
    "\n",
    "# Call the functions to get the dataframes\n",
    "airport_data = get_airport_data()\n",
    "weather_data = get_weather_data()\n",
    "\n",
    "# Merge the dataframes on the common column names\n",
    "merged_data = pd.merge(airport_data, weather_data, left_on='flight_date', right_on='date')\n",
    "\n",
    "# Plot the flight delays and weather wind speed in one plot\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.lineplot(data=df_weather, x='date', y='wspd', hue='airport_code', marker='o')\n",
    "plt.axhline(y=30, color='r', linestyle='--', label='30 kts')\n",
    "plt.title('Wind Speed Oct - Nov 2011')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Wind Speed (kts)')\n",
    "dates = df_weather['date'].unique()\n",
    "plt.xticks(dates[::2], rotation=45)\n",
    "plt.legend(title='Airport Cancellations', fontsize='small')\n",
    "plt.annotate('Take off prohibited', xy=(20, 30), xytext=(18, 36),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting with an average for all 8 airports combined - 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions to retrieve airport and weather data\n",
    "# (Assuming you have already defined these functions)\n",
    "\n",
    "# Call the functions to get the dataframes\n",
    "airport_data = get_airport_data()\n",
    "weather_data = get_weather_data()\n",
    "\n",
    "# Merge the dataframes on the common column names\n",
    "merged_data = pd.merge(airport_data, weather_data, left_on='flight_date', right_on='date')\n",
    "\n",
    "# Filter the merged data to include only the specified airports\n",
    "selected_airports = ['JFK', 'LGA', 'EWR', 'PHL', 'BOS', 'DCA', 'IAD', 'BWI']\n",
    "filtered_data = merged_data[(merged_data['origin'].isin(selected_airports)) | (merged_data['dest'].isin(selected_airports))]\n",
    "\n",
    "# Calculate the average cancellations for all selected airports\n",
    "average_cancellations = filtered_data['cancelled'].mean()\n",
    "\n",
    "# Plot the flight delays and weather wind speed in one plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.lineplot(data=weather_data, x='date', y='wspd', marker='o')\n",
    "#plt.axhline(y=30, color='r', linestyle='--')\n",
    "plt.title('Average Cancellations for JFK, LGA, EWR, PHL, BOS, DCA, IAD, BWI combined')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Cancellation Percentage')\n",
    "dates = weather_data['date'].unique()\n",
    "plt.xticks(dates[::2], rotation=45)\n",
    "plt.legend(title='Average Airport Cancellations', fontsize='small', loc='right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
